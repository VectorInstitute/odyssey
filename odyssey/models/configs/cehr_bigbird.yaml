model:
  embedding_size: 768
  time_embeddings_size: 32
  visit_order_size: 3
  type_vocab_size: 9
  max_seq_length: 2048
  depth: 6
  num_heads: 12
  intermediate_size: 3072
  learning_rate: 5.e-5
  eta_min: 1.e-8
  num_iterations: 10
  increase_factor: 2
  dropout_prob: 0.1

model_finetune:
  learning_rate: 5.e-5
  classifier_dropout: 0.1

train:
  batch_size: 32
  num_workers: 5
  gpus: 4
  nodes: 1
  max_epochs: 15
  acc: 1
  mask_prob: 0.15
  persistent_workers: True
  pin_memory: False

finetune:
  batch_size: 26
  num_workers: 3
  gpus: 1
  nodes: 1
  max_epochs: 2 # 3
  acc: 1
  patience: 10
  persistent_workers: True
  pin_memory: False
